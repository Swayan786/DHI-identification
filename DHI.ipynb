{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cd4bbb-f242-44ee-b3fb-2bf992435217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an existing experiment configuration file\n",
    "CONFIG_FILE = (\n",
    "    \"../../../experiments/interpretation/dutchf3_patch/configs/seresnet_unet.yaml\"\n",
    ")\n",
    "# number of images to score\n",
    "N_EVALUATE = 20\n",
    "# demo flag - by default notebook runs in demo mode and only fine-tunes the pre-trained model. Set to False for full re-training.\n",
    "DEMO = True\n",
    "# options are test1 or test2 - picks which Dutch F3 test set split to use\n",
    "TEST_SPLIT = \"test1\"\n",
    "\n",
    "import os\n",
    "assert os.path.isfile(CONFIG_FILE), \"Experiment config file CONFIG_FILE not found on disk\"\n",
    "assert isinstance(N_EVALUATE, int) and N_EVALUATE>0, \"Number of images to score has to be a positive integer\"\n",
    "assert isinstance(DEMO, bool), \"demo mode should be a boolean\"\n",
    "assert TEST_SPLIT == \"test1\" or TEST_SPLIT == \"test2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148848cc-521e-4274-ac7c-9694c2b3eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#library imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "import logging.config\n",
    "from os import path\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "import yacs.config\n",
    "\n",
    "import cv2\n",
    "from albumentations import Compose, HorizontalFlip, Normalize, PadIfNeeded, Resize\n",
    "from ignite.contrib.handlers import CosineAnnealingScheduler\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from ignite.engine import Events\n",
    "from ignite.metrics import Loss\n",
    "from ignite.utils import convert_tensor\n",
    "from toolz import compose\n",
    "from torch.utils import data\n",
    "\n",
    "from cv_lib.utils import load_log_configuration\n",
    "from cv_lib.event_handlers import SnapshotHandler, logging_handlers\n",
    "from cv_lib.event_handlers.logging_handlers import Evaluator\n",
    "from cv_lib.event_handlers import tensorboard_handlers\n",
    "from cv_lib.event_handlers.tensorboard_handlers import create_summary_writer\n",
    "from cv_lib.segmentation import models\n",
    "from cv_lib.segmentation.dutchf3.engine import (\n",
    "    create_supervised_evaluator,\n",
    "    create_supervised_trainer,\n",
    ")\n",
    "\n",
    "from cv_lib.segmentation.metrics import (\n",
    "    pixelwise_accuracy,\n",
    "    class_accuracy,\n",
    "    mean_class_accuracy,\n",
    "    class_iou,\n",
    "    mean_iou,\n",
    ")\n",
    "\n",
    "from cv_lib.segmentation.dutchf3.utils import (\n",
    "    current_datetime,    \n",
    "    git_branch,\n",
    "    git_hash,\n",
    "    np_to_tb,\n",
    ")\n",
    "\n",
    "from cv_lib.utils import generate_path\n",
    "\n",
    "from deepseismic_interpretation.dutchf3.data import (\n",
    "    get_patch_loader,    \n",
    "    get_test_loader,\n",
    ")\n",
    "\n",
    "from itkwidgets import view\n",
    "\n",
    "from utilities import (\n",
    "    plot_aline,\n",
    "    patch_label_2d,\n",
    "    compose_processing_pipeline,\n",
    "    output_processing_pipeline,\n",
    "    write_section_file,\n",
    "    runningScore,\n",
    "    validate_config_paths,\n",
    "    download_pretrained_model,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c0be7e-4836-4292-8bbb-f73163d45b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment configuration file\n",
    "with open(CONFIG_FILE, \"rt\") as f_read:\n",
    "    config = yacs.config.load_cfg(f_read)\n",
    "\n",
    "print(\n",
    "    f\"Configuration loaded. Please check that the DATASET.ROOT:{config.DATASET.ROOT} points to your data location.\"\n",
    ")\n",
    "print(\n",
    "    f\"To modify any of the options, please edit the configuration file {CONFIG_FILE} and reload. \\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb99b8e-6ca3-4116-b836-399a401677fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of datapoints you want to run in training or validation per batch\n",
    "# Setting to None will run whole dataset\n",
    "# useful for integration tests with a setting of something like 3\n",
    "# Use only if you want to check things are running and don't want to run\n",
    "# through whole dataset\n",
    "# The number of epochs to run in training\n",
    "max_epochs = config.TRAIN.END_EPOCH\n",
    "max_snapshots = config.TRAIN.SNAPSHOTS\n",
    "papermill = False\n",
    "dataset_root = config.DATASET.ROOT\n",
    "model_pretrained = config.MODEL.PRETRAINED if \"PRETRAINED\" in config.MODEL.keys() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d337664-55bc-42dc-b40a-fe7c82160b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read back the parameters from papermill to config if papermill was used to run this notebook\n",
    "if papermill:\n",
    "    # reduce number of images scored for testing\n",
    "    N_EVALUATE=2\n",
    "\n",
    "opts = [\n",
    "    \"DATASET.ROOT\",\n",
    "    dataset_root,\n",
    "    \"TRAIN.END_EPOCH\",\n",
    "    max_epochs,\n",
    "    \"TRAIN.SNAPSHOTS\",\n",
    "    max_snapshots,\n",
    "]\n",
    "if \"PRETRAINED\" in config.MODEL.keys():\n",
    "    opts += [\"MODEL.PRETRAINED\", model_pretrained]\n",
    "\n",
    "config.merge_from_list(opts)\n",
    "\n",
    "# download pre-trained model if possible\n",
    "config = download_pretrained_model(config)\n",
    "\n",
    "# update model pretrained (in case it was changed when the pretrained model was downloaded)\n",
    "model_pretrained = config.MODEL.PRETRAINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283eb362-a4fd-4c97-bba0-0be07be0f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEMO:\n",
    "    opts = [\n",
    "        \"TRAIN.END_EPOCH\",\n",
    "        1,\n",
    "        \"TRAIN.SNAPSHOTS\",\n",
    "        1,\n",
    "        \"TRAIN.MAX_LR\",\n",
    "        10 ** -9,\n",
    "        \"TRAIN.MIN_LR\",\n",
    "        10 ** -9,\n",
    "    ]\n",
    "    config.merge_from_list(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765069d6-ae78-4daa-b46b-88c4888e44ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seeds, and set CUDNN benchmark mode:\n",
    "torch.backends.cudnn.benchmark = config.CUDNN.BENCHMARK\n",
    "\n",
    "# Fix random seeds:\n",
    "torch.manual_seed(config.SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(config.SEED)\n",
    "np.random.seed(seed=config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee4b2ad-876b-40ba-b599-f3cac78c5a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config)\n",
    "validate_config_paths(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0479abae-afc5-473b-88e7-bae68676d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data and labels\n",
    "train_seismic = np.load(path.join(config.DATASET.ROOT, \"train/train_seismic.npy\"))\n",
    "train_labels = np.load(path.join(config.DATASET.ROOT, \"train/train_labels.npy\"))\n",
    "\n",
    "print(f\"Number of inline slices: {train_seismic.shape[0]}\")\n",
    "print(f\"Number of crossline slices: {train_seismic.shape[1]}\")\n",
    "print(f\"Depth dimension : {train_seismic.shape[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c271b63-e8ff-4617-bcec-38530119f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "view(train_labels, slicing_planes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e79de-e721-4f02-a3ad-e4cab7e1e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a crossline slice\n",
    "idx = 100\n",
    "x_in = train_seismic[idx, :, :].swapaxes(0, 1)\n",
    "x_inl = train_labels[idx, :, :].swapaxes(0, 1)\n",
    "\n",
    "plot_aline(x_in, x_inl, xlabel=\"crossline (relative)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b93f5-deaf-4be2-82cf-e9e852562a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot an inline slice\n",
    "x_cr = train_seismic[:, idx, :].swapaxes(0, 1)\n",
    "x_crl = train_labels[:, idx, :].swapaxes(0, 1)\n",
    "\n",
    "plot_aline(x_cr, x_crl, xlabel=\"inline (relative)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bda9ff-7b93-4e57-a8a7-aafb7e27240d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data and apply energy attribute \n",
    "scheduler_step = config.TRAIN.END_EPOCH // config.TRAIN.SNAPSHOTS\n",
    "\n",
    "TrainPatchLoader = get_patch_loader(config)\n",
    "\n",
    "train_set = TrainPatchLoader(\n",
    "    config,\n",
    "    split=\"train\",\n",
    "    is_transform=True,\n",
    "    augmentations=train_aug,\n",
    ")\n",
    "n_classes = train_set.n_classes\n",
    "logger.info(train_set, energy)\n",
    "val_set = TrainPatchLoader(\n",
    "    config,\n",
    "    split=\"val\",\n",
    "    is_transform=True,\n",
    "    augmentations=val_aug,\n",
    ")\n",
    "\n",
    "if papermill:\n",
    "    train_set = data.Subset(train_set, range(3))\n",
    "    val_set = data.Subset(val_set, range(3))\n",
    "elif DEMO:\n",
    "    val_set = data.Subset(val_set, range(config.VALIDATION.BATCH_SIZE_PER_GPU))\n",
    "\n",
    "logger.info(val_set, energy)\n",
    "\n",
    "train_loader = data.DataLoader(\n",
    "    train_set, energy\n",
    "    batch_size=config.TRAIN.BATCH_SIZE_PER_GPU,\n",
    "    num_workers=config.WORKERS,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = data.DataLoader(\n",
    "    val_set, energy\n",
    "    batch_size=config.VALIDATION.BATCH_SIZE_PER_GPU,\n",
    "    num_workers=config.WORKERS,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
